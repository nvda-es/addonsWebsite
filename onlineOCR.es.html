
<h1>Descriptor de im&#xE1;genes en l&#xED;nea</h1>
<ul>
<li>Autor: Larry Wang</li>
<li>Compatibilidad con NVDA: de 2018.3 a 2020.2</li>
<li>Descargar <a href="https://addons.nvda-project.org/files/get.php?file=oid-dev">versión de desarrollo</a></li>
</ul>


<p>El propósito de este complemento es añadir motores de reconocimiento de
imágenes en línea a NVDA.</p>

<p>Hay dos tipos de motores. OCR y descriptor de imágenes.</p>

<p>El OCR extrae texto de las imágenes.</p>

<p>Los descriptores de imágenes describen características visuales de la imagen
en forma de texto, tales como su descripción general, marcas de tipo de
color y demás.</p>

<p>Es necesario disponer de conexión a Internet para usar este complemento, ya
que los servicios de descripción de imágenes se proporcionan a través de
conexiones a una API en Internet.</p>

<p>En este complemento se conocen como motores.</p>

<p>Hay tres tipos de motores en este complemento.</p>

<ul>
<li>Motor de OCR en línea</li>
<li>Motor de descripción de imágenes en línea</li>
<li>OCR de Windows 10 (fuera de línea)</li>
</ul>


<p>También debes elegir la fuente de reconocimiento de la imagen.</p>

<ul>
<li>Navegador de objetos actual</li>
<li>Ventana actual en primer plano</li>
<li>Toda la pantalla</li>
<li>Datos de imagen o archivo desde el portapapeles</li>
<li>Ruta a un archivo de imagen o URL a una imagen desde el portapapeles</li>
</ul>


<h3>Órdenes de teclado</h3>

<p>Después de elegir los tipos, puedes iniciar el reconocimiento con un gesto.</p>

<p>NVDA+alt+p reconoce el objeto en función del tipo de fuente y motor
configurados y lee el resultado. Si se pulsa dos veces, abre un documento
virtual con el resultado.</p>

<p>Hay cuatro gestos más sin asignar. Por favor, asígnalos antes de usarlos.</p>

<p>Alternar entre los diferentes tipos de motores de reconocimiento.</p>

<p>Alternar entre los distintos tipos de fuentes de reconocimiento.</p>

<p>Cancelar el reconocimiento actual</p>

<p>Este gesto puede ser útil si crees que has esperado demasiado y quieres
cancelar.</p>

<p>Además hay veces en las que no te gustaría que el mensaje de reconocimiento
te molestara porque quieres revisar los mensajes que han llegado después de
iniciar el reconocimiento.</p>

<p>Mostrar el resultado anterior en un documento de resultados virtual.</p>

<p>Aunque hay una función para copiar el resultado al portapapeles, no se puede
preservar la información de posición de los caracteres, por lo que se añade
este gesto para resolver el problema.</p>

<p>Hay también cuatro gestos sin asignar para aquellos usuarios que prefieran los gestos de versiones anteriores.</p>

<p>Se recomienda usar el gesto nuevo y pasar entre motores de reconocimiento
según tus necesidades.</p>

<p>Reconoce el objeto actual del navegador de objetos con un motor OCR en línea
y lee el resultado. Si se pulsa dos veces, abre un documento virtual con el
resultado.</p>

<p>Reconoce la imagen del portapapeles con un motor OCR en línea y lee el
resultado. Si se pulsa dos veces, abre un documento virtual con el
resultado.</p>

<p>Reconoce el objeto bajo el navegador de objetos y lee el resultado. Si se
pulsa dos veces, abre un documento virtual con el resultado.</p>

<p>Reconoce la imagen del portapapeles y lee el resultado. Si se pulsa dos
veces, abre un documento virtual con el resultado.</p>

<h2>Configuración de motor</h2>

<p>Puedes elegir motores de reconocimiento y configurarlos en detalle en la
categoría <em>Online image describer</em> del diálogo de opciones de NVDA.</p>

<p>El autor de este complemento ha registrado cuentas con cuota de API gratuita
y ha configurado un servidor proxy en www.nvdacn.com para permitir que este
complemento sea más fácil de probar al principio. La cuota de pruebas está
limitada y puede ser cancelada por el proveedor de la API en cualquier
momento.</p>

<p>Se recomienda encarecidamente que registres tu propia clave siguiendo las
guías de cada motor.</p>

<p>Los siguientes ajustes se aplican a todos los motores.</p>

<ul>
<li>Copiar resultado al portapapeles después del reconocimiento: si se activa,
el texto del resultado del reconocimiento se copiará al portapapeles tras
el reconocimiento.</li>
<li>Usar mensaje explorable para el texto del resultado: si se activa, el
texto del resultado del reconocimiento se mostrará en una ventana
emergente en lugar de enviarse por mensajes de voz y braille.</li>
<li>Intercambiar el efecto de gestos repetidos con los que no están repetidos:
por defecto, sólo se muestra un documento virtual con el resultado si
pulsas el gesto correspondiente dos veces. Si haces esto frecuentemente
puedes activar esta opción, de tal forma que sólo pulses una vez para
abrir el visor de resultados.</li>
<li>Activar registro más detallado con propósitos de depuración: algunos
registros son esenciales para depurar, pero afectan al rendimiento y
consumen mucho espacio. Activa esta opción sólo si el autor del
complemento o un desarrollador de NVDA te lo pide.</li>
<li>Tipo de proxy: indica el tipo de proxy que estás usando. Si no sabes qué
es un proxy, no modifiques esta opción.</li>
<li>Dirección del proxy: URL completa del proxy. Si no sabes qué es un proxy
no cambies esta opción. Si eliges usar un proxy, este se verificará antes
de guardar. Tras la verificación, un mensaje te indicará el resultado.</li>
</ul>


<p>Los siguientes ajustes significan lo mismo en todos los motores, por lo que
se describen aquí para ahorrar espacio.</p>

<ul>
<li><p>Tipo de acceso a la API: controla cómo se accede a las conexiones de la
API corresponiente.</p>

<ul>
<li>Si eliges "Usar cuota pública", estás usando una cuota gratuita
registrada por el autor del complemento.</li>
<li>Si eliges "Usar mi propia clave de API", el complemento consumirá de
la cuota de tu propia cuenta.</li>
</ul>
</li>
<li><p>ID de aplicación, clave de API o clave secreta de API: si quieres usar la
cuota de tu propia cuenta será necesario que dispongas de los tokens de
acceso correspondientes. Algunos motores sólo necesitan una clave de
API. Algunos motores necesitan dos tokens. Estos sólo son válidos si
eliges "Usar tu propia clave de API" en tipo de acceso a la API.</p></li>
</ul>


<p>Ten en cuenta que la calidad y la precisión de los resultados dependen de
muchos factores.</p>

<ul>
<li>Modelos y técnicas empleados por el proveedor del motor</li>
<li>Calidad de la imagen subida</li>
<li>Navegador de objetos oculto tras algo</li>
<li>Resolución de pantalla</li>
</ul>


<h2>Descripción de imágenes en línea</h2>

<p>Hay tres motores disponibles.</p>

<h3>Analizador de imágenes de Microsoft Azure</h3>

<p>Este motor extrae un rico conjunto de características visuales basándose en el contenido de la imagen.</p>

<p>Este motor está sólo en inglés. Si quieres que la descripción se muestre en
otros idiomas, puedes usar el descriptor de imágenes de Microsoft Azure</p>

<p>Entre las características visuales se incluyen:</p>

<ul>
<li>Adulto - detecta si la imagen es de naturaleza pornográfica (representa la
desnudez o un acto sexual). También se detecta el contenido sexualmente
sugerente.</li>
<li>Marcas - detecta diversas marcas dentro de la imagen, incluyendo su
ubicación aproximada. El argumento de marcas sólo está disponible en
inglés.</li>
<li>Categorías - clasifica el contenido de la imagen según una taxonomía
definida en la documentación.</li>
<li>Color - determina el color más llamativo, el color predominante y si la
imagen está en blanco y negro.</li>
<li>Descripción - describe el contenido de la imagen con una frase completa en
los idiomas soportados.</li>
<li>Caras - detecta si hay caras presentes. Si las hay, identifica sus
coordenadas, género y edad.</li>
<li>Tipo de imagen - detecta si la imagen es prediseñada o se ha dibujado a
mano.</li>
<li>Objetos - detecta diversos objetos dentro de la imagen, incluyendo su
ubicación aproximada. El argumento de objetos sólo está disponible en
inglés.</li>
<li>Etiquetas - etiqueta la imagen con una lista detallada de palabras
relacionadas con su contenido.</li>
</ul>


<p>Algunas características también proporcionan detalles adicionales:</p>

<ul>
<li>Famosos - Identifica personas famosas si se detectan en la imagen.</li>
<li>Puntos de referencia - identifica puntos de referencia si se detectan en
la imagen.</li>
</ul>


<h3>Descriptor de imágenes de Microsoft Azure</h3>

<p>Este motor genera descripciones de imágenes en un lenguaje natural con
frases completas. La descripción se basa en una colección de etiquetas de
contenido, también devueltas por la operación.</p>

<p>Se puede generar más de una descripción para cada imagen. Las descripciones
se ordenan según su puntuación de confianza.</p>

<p>Hay dos ajustes para este motor.</p>

<ul>
<li>Idioma: el idioma que usará el servicio para devolver una descripción de
la imagen. Por defecto, inglés.</li>
<li>Número máximo de candidatos: cantidad máxima de descripciones candidatas
que se devuelven. Por defecto 1.</li>
</ul>


<h2>OCR en línea</h2>

<p>Los motores en línea se apoyan en el uso y presencia de los siguientes
servicios.</p>

<p><a href="https://www.nvdacn.com">https://www.nvdacn.com</a></p>

<p><a href="https://ocr.space/ocrapi">https://ocr.space/ocrapi</a></p>

<p><a href="https://azure.microsoft.com/es-es/services/cognitive-services/">https://azure.microsoft.com/es-es/services/cognitive-services/</a></p>

<p><a href="http://ai.qq.com">http://ai.qq.com</a></p>

<p><a href="http://ai.baidu.com">http://ai.baidu.com</a></p>

<p><a href="http://ai.sogou.com/">http://ai.sogou.com/</a></p>

<p><a href="https://intl.cloud.tencent.com">https://intl.cloud.tencent.com</a></p>

<h2>Motores</h2>

<p>Hay cinco motores disponibles.</p>

<h3>Tencent Cloud OCR</h3>

<p>Esta API está patrocinada por <a href="https://intl.cloud.tencent.com">Tencent
Cloud</a> y la <a href="http://www.siaa.org.cn">Accessibility Research
Association</a>, con un límite de 15000 por día.</p>

<p>Este motor soporta 19 idiomas.</p>

<ul>
<li>Una mezcla entre chino e inglés</li>
<li>Japonés</li>
<li>Coreano</li>
<li>Español</li>
<li>Francés</li>
<li>Alemán</li>
<li>Portugués</li>
<li>Vietnamita</li>
<li>Malayo</li>
<li>Ruso</li>
<li>Italiano</li>
<li>Holandés</li>
<li>Sueco</li>
<li>Finés</li>
<li>Danés</li>
<li>Noruego</li>
<li>Húngaro</li>
<li>Tailandés</li>
<li>Latín</li>
</ul>


<p>Estos son los ajustes de este motor.</p>

<ul>
<li>Idioma: idioma de reconocimiento del texto. Por defecto detectar
automáticamente.</li>
</ul>


<h3>OCR space</h3>

<p>Este servicio consta de una API de pago con cuota gratuita proporcionada por
<a href="https://ocr.space">OCR Space</a></p>

<p>Soporta 24 idiomas</p>

<ul>
<li>Árabe</li>
<li>Búlgaro</li>
<li>Chino (simplificado)</li>
<li>Chino (tradicional)</li>
<li>Croata</li>
<li>Checo</li>
<li>Danés</li>
<li>Holandés</li>
<li>Inglés</li>
<li>Finés</li>
<li>Francés</li>
<li>Alemán</li>
<li>Griego</li>
<li>Húngaro</li>
<li>Coreano</li>
<li>Italiano</li>
<li>Japonés</li>
<li>Polaco</li>
<li>Portugués</li>
<li>Ruso</li>
<li>Esloveno</li>
<li>Español</li>
<li>Sueco</li>
<li>Turco</li>
</ul>


<p>Estos son los ajustes de este motor:</p>

<ul>
<li>Idioma: idioma de reconocimiento del texto. Por defecto inglés.</li>
<li>Detectar orientación de la imagen: si se activa, la API gira
automáticamente la imagen correctamente.</li>
<li>Escalar imagen para mejorar la calidad: si se activa, la API escala la
imagen internamente. Esto puede mejorar el resultado del OCR de forma
significativa, especialmente para documentos PDF escaneados con baja
resolución.</li>
<li>Optimizar para reconocimiento de tablas: si se activa, la lógica del OCR
se asegura de que el texto del resultado interpretado siempre se devuelva
línea a línea. Esta opción se recomienda para hacer OCR en tablas,
recibos, facturas, y todos los tipos de documentos entrantes que tengan
estructura de tabla.</li>
</ul>


<p>Si quieres usar tu propia clave, también deberás especificar tu clave de
API.</p>

<p>Puedes obtener tu propia clave de API gratuita registrándote en <a href="https://ocr.space/ocrapi">OCR
space</a></p>

<p>Aquí hay una guía simple.</p>

<p>Busca el enlace "Register for free API key"</p>

<p>Púlsalo y llegarás a un formulario que hay que rellenar.</p>

<p>El formulario te pide que introduzcas los siguientes datos</p>

<ul>
<li>Dirección de correo electrónico</li>
<li>Nombre</li>
<li>Apellidos</li>
<li>¿Cómo tienes pensado usar la API del OCR?</li>
</ul>


<p>Después de rellenarlo y enviarlo, puede que tengas que superar un captcha</p>

<p>A continuación, recibirás un correo electrónico de confirmación</p>

<p>Busca el enlace "Yes, subscribe me to this list." en ese correo. Accede a
ese enlace y recibirás la clave de API pronto.</p>

<h3>Microsoft Azure OCR</h3>

<p>Este motor utiliza la API del OCR de los Servicios Cognitivos de Visión
Artificial de Microsoft Azure.</p>

<p>Soporta 24 idiomas, incluyendo</p>

<ul>
<li>Chino simplificado</li>
<li>Chino tradicional</li>
<li>Checo</li>
<li>Danés</li>
<li>Holandés</li>
<li>Inglés</li>
<li>Finés</li>
<li>Francés</li>
<li>Alemán</li>
<li>Griego</li>
<li>Húngaro</li>
<li>Italiano</li>
<li>Japonés</li>
<li>Coreano</li>
<li>Noruego</li>
<li>Polaco</li>
<li>Portugués</li>
<li>Ruso</li>
<li>Español</li>
<li>Sueco</li>
<li>Turco</li>
<li>Árabe</li>
<li>Rumano</li>
<li>Serbio cirílico</li>
<li>Serbio latino</li>
<li>Eslovaco</li>
</ul>


<p>Estos son los ajustes de este motor:</p>

<ul>
<li>Idioma: idioma de reconocimiento del texto. Por defecto detectar
automáticamente.</li>
<li>Detectar orientación de la imagen: si se activa, la API gira
automáticamente la imagen correctamente.</li>
</ul>


<p>Si quieres usar tu propia clave, deberías obtener una clave de suscripción
para utilizar la API de Visión Artificial de Microsoft desde el siguiente
enlace:</p>

<p>Paso 1: crea una cuenta en el <a href="https://azure.microsoft.com/es-es/try/cognitive-services/">sitio web de
Azure</a></p>

<p>Ten en cuenta que debes crear una clave para la API de visión artificial. Es
el primer botón "Obtener clave de API" que encuentras con la navegación de
una sola letra. Actualmente Microsoft ofrece la opción de crear una clave de
prueba que funciona durante 7 días. También puedes crear una cuenta gratuita
de Azure para tener más pruebas. Al registrarse será obligatorio aportar los
datos de una tarjeta de crédito. Si ya tienes una cuenta con suscripción,
puedes saltarte este paso.</p>

<p>Paso 2: despliega los servicios cognitivos</p>

<p>Ahora tienes una cuenta de Azure.</p>

<p>Primero, inicia sesión en el <a href="https://portal.azure.com">portal de Azure</a></p>

<p>Espera hasta que oigas el mensaje "El portal está listo, has iniciado sesión
en el portal de Azure".</p>

<p>Busca el enlace llamado "Todos los recursos" después del botón "Todos los
servicios" y actívalo.</p>

<p>Espera hasta que oigas el mensaje "La hoja Todos los recursos está
lista". El foco se encontrará en un cuadro de edición. Pulsa shift+tab hasta
que llegues a un elemento de menú llamado Agregar y actívalo.</p>

<p>Espera hasta que oigas el mensaje "Buscar en marketplace", escribe cognitive
services y pulsa flecha abajo.</p>

<p>Espera hasta que oigas el mensaje Lista de opciones Cognitive services 1 de
5, y a continuación pulsa intro.</p>

<p>Espera hasta que oigas el mensaje La hoja Cognitive Services está
lista. Pulsa tab o la letra b para buscar un botón llamado Crear y actívalo.</p>

<p>Espera hasta que oigas el mensaje La hoja Crear está lista. El foco estará
en un cuadro de edición. Escribe un nombre para el recurso. Ten en cuenta
que el nombre del recurso sólo puede incluir caracteres alfanuméricos, '<em>' y
'-', y no puede terminar en '</em>' ni '-'.</p>

<p>Yo elijo NVDA_OCR.</p>

<p>Pulsa tab para ir al cuadro combinado de suscripción. Normalmente puedes
dejarlo como está.</p>

<p>Pulsa tabulador para ir al cuadro combinado de región. Elige una que se encuentre cerca de tu ubicación actual.</p>

<p>Recuerda esta región, ya que tendrás que especificarla en la configuración
del motor.</p>

<p>Pulsa tabulador para ir al cuadro combinado de capa. Normalmente una capa
gratuita como f0 es adecuada. Si no es suficiente para ti, puedes elegir
otra capa después de leer todos los detalles del precio en el enlace "Ver
detalles completos del precio".</p>

<p>Tabula hasta que llegues a un cuadro de edición llamado Crear nuevo grupo de recursos. Deberías crear uno si no tienes ninguno. Busca el botón Crear Nuevo.</p>

<p>Después pulsa tab hasta el botón Crear y actívalo para crear este recurso.</p>

<p>Espera hasta que oigas el mensaje "Despliegue completado_".</p>

<p>Después busca el botón "Ir al recurso". A veces es necesario subir y activar
el botón Notificaciones para encontrar este botón.</p>

<p>Espera hasta que oigas el mensaje La hoja Primeros pasos está lista.</p>

<p>Busca el enlace llamado Claves y actívalo.</p>

<p>Espera hasta que oigas el mensaje La hoja Gestionar claves está lista.</p>

<p>Busca un cuadro de edición llamado Clave 1 o Clave 2. El contenido de ese
cuadro de edición es la clave de API que se necesita para la configuración
del motor. Pulsa ctrl+c para copiarla al portapapeles</p>

<p>A continuación, puedes rellenar estas dos opciones, necesarias si usas tu
propia clave de API.</p>

<ul>
<li>Región de recursos de Azure: la región que elegiste al desplegar los
servicios cognitivos en el portal de Azure.</li>
<li>Clave de API: la clave que obtienes al desplegar con éxito los servicios
cognitivos en el portal de Azure, se recomienda la clave 2.</li>
</ul>


<h3>Baidu OCR</h3>

<p>Este también ofrece una API de pago con cuota gratuita proporcionada por
Baidu.</p>

<p>El OCR de Baidu soporta 10 idiomas, incluyendo</p>

<ul>
<li>Una mezcla entre chino e inglés</li>
<li>Inglés</li>
<li>Portugués</li>
<li>Francés</li>
<li>Alemán</li>
<li>Italiano</li>
<li>Español</li>
<li>Ruso</li>
<li>Japonés</li>
<li>Coreano</li>
</ul>


<p>Este motor también puede obtener la posición de cada carácter</p>

<p>Aquí están sus ajustes:</p>

<ul>
<li><p>Obtener posición de cada carácter: permite operar de forma más precisa en
algunas aplicaciones inaccesibles. Al activar esta opción el
reconocimiento se volverá algo más lento.</p></li>
<li><p>Usar API precisa: si se habilita usará otro punto de conexión. Esta
conexión precisa dura más tiempo, pero tiene mejor calidad y (si usas tu
propia clave de API) el precio es más alto.</p></li>
</ul>


<p>Tiene cuatro conexiones con límites de cuota separados.</p>

<ul>
<li>OCR básico sin información sobre la ubicación del texto. Actualmente 50000
veces al día.</li>
<li>OCR básico con información sobre la ubicación del texto. Actualmente 500
veces al día.</li>
<li>OCR preciso sin información sobre la ubicación del texto. Actualmente 500
veces al día.</li>
<li>Preciso con información sobre la ubicación del texto. Actualmente 50 veces
al día.</li>
</ul>


<p>Si pulsas el gesto que sólo lee el resultado, usarás conexiones sin información de posición del texto.</p>

<p>Si pulsas el gesto que muestra el visor de resultados, usarás las conexiones que muestran información sobre la ubicación del texto.</p>

<p>Aunque proporciona una cuota gratuita bastante generosa, su sitio web sólo
está en chino y no es muy accesible.</p>

<h3>Tencent AI OCR</h3>

<p>Esta API tiene uso gratuito, con un límite de frecuencia de dos consultas por segundo.</p>

<p>Si quieres sobrepasar el límite, puedes registrar tu propia clave de API. La
web de esta API se encuentra sólo en chino y no es muy accesible.</p>

<p>No hay información sobre los idiomas soportados en la documentación de esta API. Según las pruebas realizadas, se soportan el chino, el inglés y una mezcla de ambos.</p>

<p>No hay configuración adicional para esta API.</p>

<h2>Registro de cambios</h2>

<h3>0.19</h3>

<ul>
<li>Compatible con NVDA 2020.2</li>
<li>Se ha añadido el OCR de Tencent Cloud, patrocinado por <a href="https://intl.cloud.tencent.com">Tencent
Cloud</a> y la <a href="http://www.siaa.org.cn">Accessibility Research
Association</a></li>
<li>Se han eliminado el OCR Sougou y el motor de aprendizaje automático de
Oliver Edholm, ya que no están disponibles.</li>
<li>Se corrige la conexión pública al <a href="https://www.nvdacn.com">sitio de NVDA en
China</a></li>
</ul>


<h3>0.18</h3>

<ul>
<li>Compatible con Python 3</li>
<li>Se introducen los conceptos de tipo de fuente de reconocimiento y tipo de
motor para reducir el uso de gestos.</li>
<li>Se añade un gesto nuevo sin asignar para alternar entre los diferentes
tipos de fuentes de reconocimiento.</li>
<li>Se añade un nuevo gesto sin asignar para alternar entre los diferentes
tipos de motores de reconocimiento.</li>
<li>Se añade un nuevo gesto para reconocer según los ajustes de fuente de la
imagen y tipo de motor.</li>
<li>Se añade un nuevo gesto sin asignar para mostrar el resultado anterior en
un documento de resultado virtual.</li>
</ul>


<h3>0.17</h3>

<ul>
<li><p>Se han corregido los siguientes problemas:</p>

<ul>
<li>Se salta directamente al panel cuando se cambia a Descriptor de
imágenes en línea en el diálogo de opciones</li>
<li>Errata de descripción en el analizador de Azure</li>
</ul>
</li>
</ul>


<h3>0.16</h3>

<ul>
<li>Se ha añadido un gesto para cancelar el reconocimiento</li>
<li><p>Se han corregido los siguientes problemas:</p>

<ul>
<li>No se anunciaban los cambios de estado en la lista de casillas de
verificación</li>
<li>Intercambiar el efecto de gestos repetidos no funcionaba en Online
Image Describer</li>
</ul>
</li>
</ul>


<h3>0.15</h3>

<ul>
<li>Se ha añadido una opción para mostrar una ventana que contiene el mensaje
en vez de usar mensajes de voz y braille para el texto de los resultados</li>
<li>Las casillas de verificación con las características visuales del
analizador de imágenes de Microsoft Azure ahora están en una lista.</li>
<li><p>Se han corregido los siguientes problemas:</p>

<ul>
<li>No se podía cargar un archivo de imagen JPG desde el portapapeles</li>
<li>El objeto del documento con el resultado no se mostraba después del
reconocimiento.</li>
<li>La posición en los objetos del documento de resultados no era fiable
si la imagen se redimensionaba internamente.</li>
<li>El resultado del analizador de imágenes de Microsoft Azure se mostraba
en una línea, complicando la navegación.</li>
</ul>
</li>
</ul>


<h3>0.14</h3>

<ul>
<li><p>Corregidos algunos fallos:</p>

<ul>
<li>No podías usar tu propia clave de API en los motores de Microsoft
Azure</li>
<li>No se podía obtener el texto del resultado si había una pantalla
braille</li>
</ul>
</li>
</ul>


<h3>0.13</h3>

<ul>
<li>Ahora el complemento funciona al recargar los plugins sin reiniciar
(NVDA+ctrl+f3)</li>
</ul>


<h3>0.12</h3>

<ul>
<li>Corregido el mensaje en modo exploración del descriptor de imágenes de
Microsoft Azure</li>
<li>El tono del color ahora se representa con la descripción de colores de
NVDA.</li>
<li>Se ha mejorado el formato de resultado del analizador de imágenes de
Microsoft Azure</li>
<li>Se ha mejorado la documentación a partir de los comentarios de la revisión</li>
<li>Corregida inconsistencia de gestos.</li>
<li>Ctrl+shift+NVDA para el portapapeles y NVDA+alt para el navegador de
objetos</li>
<li>Se ha corregido un error de información ausente de imagen mientras se
reconocía.</li>
</ul>


<h3>0.11</h3>

<ul>
<li>Se ha añadido la capacidad de describir imágenes</li>
<li>Se ha cambiado la descripción corta del complemento a Online Image
Describer</li>
</ul>


<h3>0.10</h3>

<ul>
<li>Corregido un error al utilizar la clave propia de API del usuario en la
API de Sougou.</li>
<li>Corregido un problema de panel desconocido añadiendo los ajustes a
supportedSettings</li>
</ul>


<h3>0.9</h3>

<ul>
<li>Corregido un problema que provocaba que no hubiera efecto alguno al
realizar una doble pulsación.</li>
<li>Se ha revisado la documentación para reflejar los cambios más recientes en
el código.</li>
<li>Se ha clarificado qué tipo de imágenes del portapapeles se soportan y cómo
copiarlas para reconocerlas.</li>
<li>Solucionado el problema que impedía abrir el visor de resultados cuando se
hacía el reconocimiento desde el portapapeles.</li>
<li>Se ha añadido soporte para reconocer una imagen desde una ruta de archivo
local copiada al portapapeles.</li>
</ul>


<h3>0.8</h3>

<ul>
<li>Se ha añadido un aviso más amigable si el resultado del reconocimiento
está vacío.</li>
<li>Resuelto otro problema que provocaba un mal funcionamiento si la ruta a
los archivos de configuración contiene caracteres no ASCII</li>
</ul>


<h3>0.6</h3>

<ul>
<li>Se han añadido opciones de proxy para aquellos usuarios que accedan a
Internet a través de un proxy específico.</li>
<li>Se han añadido varias opciones generales.</li>
<li>Se ha corregido un error de decodificación Unicode causado por el envío de
una URL Unicode a urllib3.</li>
</ul>


<h3>0.5</h3>

<ul>
<li>Se ha corregido un error Unicode que ocurría si el motor del OCR subía el
archivo de imagen directamente en vez de codificarlo en Base64.</li>
<li>Modificado el gesto para reconocer el portapapeles a ctrl+NVDA+shift+r, ya
que NVDA+shift+r se usa en Word y Excel para definir cabeceras de fila en
tablas, o para eliminar las definiciones si se pulsan dos veces.</li>
</ul>


<h3>0.4</h3>

<ul>
<li>Se ha corregido un error de instalación que ocurría cuando la ruta a la
configuración contenía caracteres no ASCII</li>
<li>Se ha cambiado el gesto para evitar una colisión con Golden Cursor.</li>
<li>Se ha cambiado el motor por defecto a Microsoft Azure, ya que es capaz de
detectar automáticamente el idioma del texto.</li>
</ul>


<h3>0.3</h3>

<ul>
<li>Se ha añadido documentación detallada sobre cómo obtener la clave de API
del OCR de Microsoft Azure</li>
<li>Se ha corregido un problema con las nuevas instalaciones.</li>
<li>Eliminado el OCR automático, ya que esta función es problemática y puede
resultar confusa con los motores en línea. AutoOCR se liberará como un
complemento separado cuando sea suficientemente estable.</li>
</ul>


